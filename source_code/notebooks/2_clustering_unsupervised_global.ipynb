{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/daniel/anaconda3/envs/Secuencias/lib/python3.10/site-packages (1.1.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/daniel/anaconda3/envs/Secuencias/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/daniel/.local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/daniel/.local/lib/python3.10/site-packages (from scikit-learn) (1.23.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/daniel/.local/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, MiniBatchKMeans, Birch, AffinityPropagation, AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_performance_clustering(data, labels):\n",
    "    siluetas = metrics.silhouette_score(data, labels, metric='euclidean')\n",
    "    calinski = metrics.calinski_harabasz_score(data, labels)\n",
    "    davies = metrics.davies_bouldin_score(data, labels)\n",
    "\n",
    "    return siluetas, calinski, davies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    0 : \"absorption\",\n",
    "    1 : \"enantioselectivity\",\n",
    "    2 : \"localization\",\n",
    "    3 : \"T50\"\n",
    "}\n",
    "method = {\n",
    "    0:\"FFT\",\n",
    "    1:\"NLP\",\n",
    "    2:\"Properties\"\n",
    "}\n",
    "bioembedding = {\n",
    "    0:\"bepler\",\n",
    "    1:\"esm\",\n",
    "    2:\"fasttext\",\n",
    "    3:\"plus_rnn\",\n",
    "    4:\"prottrans\"\n",
    "}\n",
    "distances = {\n",
    "    1 : \"Euclidean\",\n",
    "    2 : \"Braycurtis\",\n",
    "    3 : \"Canberra\",\n",
    "    4 : \"Chebyshev\",\n",
    "    5 : \"Cityblock\",\n",
    "    6 : \"Correlation\",\n",
    "    7 : \"Cosine\",\n",
    "    8 : \"Minkowski\",\n",
    "    9 : \"Hamming\"\n",
    "}\n",
    "\n",
    "resultados = [\"\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (2). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (2). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (2). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (7). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (29). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (29). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (10). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_birch.py:752: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (2). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:236: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:236: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:236: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "C:\\Users\\0\\Documents\\GitHub\\Secuencias\\venv\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:236: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for a in range(0,4):\n",
    "    for b in range(0,3):\n",
    "        if b == 1:\n",
    "            for c in range(0,5):\n",
    "                if a == 0:\n",
    "                    df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/\"+bioembedding[c]+\"-absortion.csv\")\n",
    "                else:\n",
    "                    df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/\"+bioembedding[c]+\"-\"+dataset[a]+\".csv\")\n",
    "                df_id = df_data['id']\n",
    "                ignore_columns = pd.DataFrame()\n",
    "                ignore_columns['id'] = df_data['id']\n",
    "                ignore_columns['target'] = df_data['target']\n",
    "\n",
    "                df_data = df_data.drop(columns=['id', 'target'])\n",
    "\n",
    "                '''------------KMEANS-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "                    kmeans.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"k-means-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['K-means-{}'.format(k)]=kmeans.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_kmeans.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/kmeans_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    kmeans = KMeans(n_clusters=(int(strategies[0][8]+strategies[0][9])), random_state=0)\n",
    "                except:\n",
    "                    kmeans = KMeans(n_clusters=(int(strategies[0][8])), random_state=0)\n",
    "                kmeans.fit(df_data)\n",
    "                ignore_columns['labels'] = kmeans.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_kmeans.csv\")\n",
    "\n",
    "                '''------------DBSCAN-----------------------------------------------------------\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    dbscan = DBSCAN(eps=k,min_samples=2)\n",
    "                    dbscan.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, dbscan.labels_)\n",
    "                    row = [\"dbscan-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['K-means{}'.format(k)]=kmeans.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_dbscan.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/dbscan_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    dbscan = KMeans(eps=(int(strategies[0][8]+strategies[0][9])), min_samples=2)\n",
    "                except:\n",
    "                    dbscan = KMeans(eps=(int(strategies[0][8])), min_samples=2)\n",
    "                dbscan.fit(df_data)\n",
    "                ignore_columns['labels'] = dbscan.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_dbscan.csv\")\n",
    "                '''\n",
    "                '''------------MEANSHIFT-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    meanshift = MeanShift(bandwidth=k)\n",
    "                    meanshift.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"meanshift-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['meanshift-{}'.format(k)]=meanshift.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_meanshift.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/meanshift_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    meanshift = MeanShift(bandwidth=(int(strategies[0][10]+strategies[0][11])))\n",
    "                except:\n",
    "                    meanshift = MeanShift(bandwidth=(int(strategies[0][10])))\n",
    "                meanshift.fit(df_data)\n",
    "                ignore_columns['labels'] = meanshift.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_meanshift.csv\")\n",
    "\n",
    "                '''------------BIRCH-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    birch = Birch(n_clusters=k, threshold=0.006)\n",
    "                    birch.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, birch.labels_)\n",
    "                    row = [\"birch-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['birch-{}'.format(k)]=birch.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_birch.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/birch_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    birch = Birch(n_clusters=(int(strategies[0][6]+strategies[0][7])), threshold=0.1)\n",
    "                except:\n",
    "                    birch = Birch(n_clusters=(int(strategies[0][6])), threshold=0.1)\n",
    "                birch.fit(df_data)\n",
    "                ignore_columns['labels'] = birch.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_birch.csv\")\n",
    "\n",
    "                '''------------AFFINITY-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in np.arange(0.5,1.0,0.05):\n",
    "                    affinity = AffinityPropagation(damping=k)\n",
    "                    affinity.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"affinity-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['affinity-{}'.format(k)]=affinity.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_affinity.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/affinity_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    damp = strategies[0][9]+strategies[0][10]+strategies[0][11]+strategies[0][12]\n",
    "                    affinity = AffinityPropagation(damping=(float(damp)))\n",
    "                except:\n",
    "                    damp = strategies[0][9]+strategies[0][10]+strategies[0][11]\n",
    "                    affinity = AffinityPropagation(damping=(float(damp)))\n",
    "                affinity.fit(df_data)\n",
    "                ignore_columns['labels'] = affinity.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_affinity.csv\")\n",
    "\n",
    "                '''------------AGLOMERATIVE-----------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=k)\n",
    "                    aglomerative.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, aglomerative.labels_)\n",
    "                    row = [\"aglomerative-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['aglomerative-{}'.format(k)]=aglomerative.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/results_aglomerative.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/aglomerative_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13]+strategies[0][14])))\n",
    "                except:\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13])))\n",
    "                aglomerative.fit(df_data)\n",
    "                ignore_columns['labels'] = aglomerative.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/\"+bioembedding[c]+\"/unsupervised_clustering_sequences_aglomerative.csv\")\n",
    "        if b == 0:\n",
    "            for c in range (0,8):\n",
    "                if a == 0:\n",
    "                    df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/fft-Group_\"+str(c)+\"-absortion.csv\")\n",
    "                else:\n",
    "                    df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/fft-Group_\"+str(c)+\"-\"+dataset[a]+\".csv\")\n",
    "                df_id = df_data['id']\n",
    "                ignore_columns = pd.DataFrame()\n",
    "                ignore_columns['id'] = df_data['id']\n",
    "                ignore_columns['target'] = df_data['target']\n",
    "\n",
    "                df_data = df_data.drop(columns=['id', 'target'])\n",
    "\n",
    "                '''------------KMEANS-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "                    kmeans.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"k-means-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['K-means-{}'.format(k)]=kmeans.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_kmeans.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/kmeans_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    kmeans = KMeans(n_clusters=(int(strategies[0][8]+strategies[0][9])), random_state=0)\n",
    "                except:\n",
    "                    kmeans = KMeans(n_clusters=(int(strategies[0][8])), random_state=0)\n",
    "                kmeans.fit(df_data)\n",
    "                ignore_columns['labels'] = kmeans.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_kmeans.csv\")\n",
    "\n",
    "                '''------------DBSCAN-----------------------------------------------------------'''\n",
    "                '''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in np.arange(0.05, 1, 0.05):\n",
    "                    dbscan = DBSCAN(eps=k,min_samples=10)\n",
    "                    dbscan.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, dbscan.labels_)\n",
    "                    row = [\"dbscan-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['K-means{}'.format(k)]=kmeans.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_dbscan.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/dbscan_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    dbscan = KMeans(eps=(int(strategies[0][8]+strategies[0][9])), min_samples=2)\n",
    "                except:\n",
    "                    dbscan = KMeans(eps=(int(strategies[0][8])), min_samples=2)\n",
    "                dbscan.fit(df_data)\n",
    "                ignore_columns['labels'] = dbscan.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_dbscan.csv\")\n",
    "                '''\n",
    "                '''------------MEANSHIFT-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    meanshift = MeanShift(bandwidth=k)\n",
    "                    meanshift.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"meanshift-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['meanshift-{}'.format(k)]=meanshift.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_meanshift.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/meanshift_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    meanshift = MeanShift(bandwidth=(int(strategies[0][10]+strategies[0][11])))\n",
    "                except:\n",
    "                    meanshift = MeanShift(bandwidth=(int(strategies[0][10])))\n",
    "                meanshift.fit(df_data)\n",
    "                ignore_columns['labels'] = meanshift.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_meanshift.csv\")\n",
    "\n",
    "                '''------------BIRCH-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    birch = Birch(n_clusters=k, threshold=0.006)\n",
    "                    birch.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, birch.labels_)\n",
    "                    row = [\"birch-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['birch-{}'.format(k)]=birch.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_birch.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/birch_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    birch = Birch(n_clusters=(int(strategies[0][6]+strategies[0][7])), threshold=0.1)\n",
    "                except:\n",
    "                    birch = Birch(n_clusters=(int(strategies[0][6])), threshold=0.1)\n",
    "                birch.fit(df_data)\n",
    "                ignore_columns['labels'] = birch.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_birch.csv\")\n",
    "\n",
    "                '''------------AFFINITY-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in np.arange(0.5,1.0,0.05):\n",
    "                    affinity = AffinityPropagation(damping=k)\n",
    "                    affinity.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"affinity-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['affinity-{}'.format(k)]=affinity.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_affinity.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/affinity_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    damp = strategies[0][9]+strategies[0][10]+strategies[0][11]+strategies[0][12]\n",
    "                    affinity = AffinityPropagation(damping=(float(damp)))\n",
    "                except:\n",
    "                    damp = strategies[0][9]+strategies[0][10]+strategies[0][11]\n",
    "                    affinity = AffinityPropagation(damping=(float(damp)))\n",
    "                affinity.fit(df_data)\n",
    "                ignore_columns['labels'] = affinity.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_affinity.csv\")\n",
    "\n",
    "                '''------------AGLOMERATIVE-----------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=k)\n",
    "                    aglomerative.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, aglomerative.labels_)\n",
    "                    row = [\"aglomerative-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['aglomerative-{}'.format(k)]=aglomerative.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_aglomerative.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/aglomerative_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13]+strategies[0][14])))\n",
    "                except:\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13])))\n",
    "                aglomerative.fit(df_data)\n",
    "                ignore_columns['labels'] = aglomerative.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_aglomerative.csv\")\n",
    "        if b == 2:\n",
    "            for c in range(0,8):\n",
    "                if a == 0:\n",
    "                    df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/physicochemical-Group_\"+str(c)+\"-absortion.csv\")\n",
    "                else:\n",
    "                    df_data = pd.read_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/physicochemical-Group_\"+str(c)+\"-\"+dataset[a]+\".csv\")\n",
    "                df_id = df_data['id']\n",
    "                ignore_columns = pd.DataFrame()\n",
    "                ignore_columns['id'] = df_data['id']\n",
    "                ignore_columns['target'] = df_data['target']\n",
    "\n",
    "                df_data = df_data.drop(columns=['id', 'target'])\n",
    "\n",
    "                '''------------KMEANS-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "                    kmeans.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"k-means-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['K-means-{}'.format(k)]=kmeans.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_kmeans.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/kmeans_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    kmeans = KMeans(n_clusters=(int(strategies[0][8]+strategies[0][9])), random_state=0)\n",
    "                except:\n",
    "                    kmeans = KMeans(n_clusters=(int(strategies[0][8])), random_state=0)\n",
    "                kmeans.fit(df_data)\n",
    "                ignore_columns['labels'] = kmeans.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_kmeans.csv\")\n",
    "\n",
    "                '''------------DBSCAN-----------------------------------------------------------\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    dbscan = DBSCAN(eps=k,min_samples=2)\n",
    "                    dbscan.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, dbscan.labels_)\n",
    "                    row = [\"dbscan-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['K-means{}'.format(k)]=kmeans.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_dbscan.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/dbscan_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    dbscan = KMeans(eps=(int(strategies[0][8]+strategies[0][9])), min_samples=2)\n",
    "                except:\n",
    "                    dbscan = KMeans(eps=(int(strategies[0][8])), min_samples=2)\n",
    "                dbscan.fit(df_data)\n",
    "                ignore_columns['labels'] = dbscan.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_dbscan.csv\")\n",
    "                '''\n",
    "                '''------------MEANSHIFT-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    meanshift = MeanShift(bandwidth=k)\n",
    "                    meanshift.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"meanshift-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['meanshift{}'.format(k)]=meanshift.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_meanshift.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/meanshift_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    meanshift = MeanShift(bandwidth=(int(strategies[0][10]+strategies[0][11])))\n",
    "                except:\n",
    "                    meanshift = MeanShift(bandwidth=(int(strategies[0][10])))\n",
    "                meanshift.fit(df_data)\n",
    "                ignore_columns['labels'] = meanshift.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_meanshift.csv\")\n",
    "\n",
    "                '''------------BIRCH-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    birch = Birch(n_clusters=k, threshold=0.006)\n",
    "                    birch.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, birch.labels_)\n",
    "                    row = [\"birch-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['birch-{}'.format(k)]=birch.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_birch.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/birch_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    birch = Birch(n_clusters=(int(strategies[0][6]+strategies[0][7])), threshold=0.1)\n",
    "                except:\n",
    "                    birch = Birch(n_clusters=(int(strategies[0][6])), threshold=0.1)\n",
    "                birch.fit(df_data)\n",
    "                ignore_columns['labels'] = birch.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_birch.csv\")\n",
    "\n",
    "                '''------------AFFINITY-----------------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in np.arange(0.5,1.0,0.05):\n",
    "                    affinity = AffinityPropagation(damping=k)\n",
    "                    affinity.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, kmeans.labels_)\n",
    "                    row = [\"affinity-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['affinity-{}'.format(k)]=affinity.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_affinity.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/affinity_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    damp = strategies[0][9]+strategies[0][10]+strategies[0][11]+strategies[0][12]\n",
    "                    affinity = AffinityPropagation(damping=(float(damp)))\n",
    "                except:\n",
    "                    damp = strategies[0][9]+strategies[0][10]+strategies[0][11]\n",
    "                    affinity = AffinityPropagation(damping=(float(damp)))\n",
    "                affinity.fit(df_data)\n",
    "                ignore_columns['labels'] = affinity.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_affinity.csv\")\n",
    "\n",
    "                '''------------AGLOMERATIVE-----------------------------------------------------'''\n",
    "                df_concat = []\n",
    "                matrix_result = []\n",
    "                df_sub = pd.DataFrame()\n",
    "                df_sub['secuencia']=df_id\n",
    "                for k in range(2, 30):\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=k)\n",
    "                    aglomerative.fit(df_data)\n",
    "                    siluetas, calinski, davies = get_performance_clustering(df_data, aglomerative.labels_)\n",
    "                    row = [\"aglomerative-{}\".format(k), siluetas, calinski, davies]\n",
    "                    matrix_result.append(row)\n",
    "                    df_sub['aglomerative-{}'.format(k)]=aglomerative.labels_\n",
    "\n",
    "                df_explore = pd.DataFrame(matrix_result, columns=['strategy', 'siluetas', 'calinski', 'davies'])\n",
    "                df_explore.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/results_aglomerative.csv\")\n",
    "                df_sub.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/aglomerative_labels.csv\")\n",
    "\n",
    "                highest_siluetas = np.max(df_explore['siluetas'])\n",
    "                highest_calinski = np.max(df_explore['calinski'])\n",
    "\n",
    "                df_filter_by_siluetas = df_explore.loc[df_explore['siluetas'] >= highest_siluetas]\n",
    "                df_filter_by_calinski = df_explore.loc[df_explore['calinski'] >= highest_calinski]\n",
    "\n",
    "                df_concat = pd.concat([df_filter_by_siluetas, df_filter_by_calinski])\n",
    "                strategies = df_concat['strategy'].unique()\n",
    "                frase = dataset[a]+\"/\"+method[b]+\"/Group\"+str(c)+\" dio \"+strategies[0]\n",
    "                resultados.append(frase)\n",
    "                try:\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13]+strategies[0][14])))\n",
    "                except:\n",
    "                    aglomerative = AgglomerativeClustering(n_clusters=(int(strategies[0][13])))\n",
    "                aglomerative.fit(df_data)\n",
    "                ignore_columns['labels'] = aglomerative.labels_\n",
    "\n",
    "                ignore_columns.to_csv(\"../../results_demo/\"+dataset[a]+\"/\"+method[b]+\"/Group_\"+str(c)+\"/unsupervised_clustering_sequences_aglomerative.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n 'absorption/FFT/Group0 dio k-means-2',\n 'absorption/FFT/Group0 dio meanshift-2',\n 'absorption/FFT/Group0 dio birch-2',\n 'absorption/FFT/Group0 dio affinity-0.5',\n 'absorption/FFT/Group0 dio aglomerative-2',\n 'absorption/FFT/Group1 dio k-means-2',\n 'absorption/FFT/Group1 dio meanshift-2',\n 'absorption/FFT/Group1 dio birch-2',\n 'absorption/FFT/Group1 dio affinity-0.5',\n 'absorption/FFT/Group1 dio aglomerative-2',\n 'absorption/FFT/Group2 dio k-means-2',\n 'absorption/FFT/Group2 dio meanshift-2',\n 'absorption/FFT/Group2 dio birch-8',\n 'absorption/FFT/Group2 dio affinity-0.5',\n 'absorption/FFT/Group2 dio aglomerative-8',\n 'absorption/FFT/Group3 dio k-means-28',\n 'absorption/FFT/Group3 dio meanshift-2',\n 'absorption/FFT/Group3 dio birch-29',\n 'absorption/FFT/Group3 dio affinity-0.5',\n 'absorption/FFT/Group3 dio aglomerative-29',\n 'absorption/FFT/Group4 dio k-means-3',\n 'absorption/FFT/Group4 dio meanshift-2',\n 'absorption/FFT/Group4 dio birch-2',\n 'absorption/FFT/Group4 dio affinity-0.5',\n 'absorption/FFT/Group4 dio aglomerative-2',\n 'absorption/FFT/Group5 dio k-means-2',\n 'absorption/FFT/Group5 dio meanshift-2',\n 'absorption/FFT/Group5 dio birch-2',\n 'absorption/FFT/Group5 dio affinity-0.5',\n 'absorption/FFT/Group5 dio aglomerative-2',\n 'absorption/FFT/Group6 dio k-means-2',\n 'absorption/FFT/Group6 dio meanshift-2',\n 'absorption/FFT/Group6 dio birch-2',\n 'absorption/FFT/Group6 dio affinity-0.5',\n 'absorption/FFT/Group6 dio aglomerative-2',\n 'absorption/FFT/Group7 dio k-means-2',\n 'absorption/FFT/Group7 dio meanshift-2',\n 'absorption/FFT/Group7 dio birch-2',\n 'absorption/FFT/Group7 dio affinity-0.5',\n 'absorption/FFT/Group7 dio aglomerative-2',\n 'absorption/NLP/bepler dio k-means-3',\n 'absorption/NLP/bepler dio meanshift-2',\n 'absorption/NLP/bepler dio birch-3',\n 'absorption/NLP/bepler dio affinity-0.5',\n 'absorption/NLP/bepler dio aglomerative-3',\n 'absorption/NLP/esm dio k-means-2',\n 'absorption/NLP/esm dio meanshift-2',\n 'absorption/NLP/esm dio birch-2',\n 'absorption/NLP/esm dio affinity-0.5',\n 'absorption/NLP/esm dio aglomerative-2',\n 'absorption/NLP/fasttext dio k-means-2',\n 'absorption/NLP/fasttext dio meanshift-2',\n 'absorption/NLP/fasttext dio birch-2',\n 'absorption/NLP/fasttext dio affinity-0.5',\n 'absorption/NLP/fasttext dio aglomerative-2',\n 'absorption/NLP/plus_rnn dio k-means-2',\n 'absorption/NLP/plus_rnn dio meanshift-2',\n 'absorption/NLP/plus_rnn dio birch-2',\n 'absorption/NLP/plus_rnn dio affinity-0.5',\n 'absorption/NLP/plus_rnn dio aglomerative-2',\n 'absorption/NLP/prottrans dio k-means-2',\n 'absorption/NLP/prottrans dio meanshift-2',\n 'absorption/NLP/prottrans dio birch-2',\n 'absorption/NLP/prottrans dio affinity-0.5',\n 'absorption/NLP/prottrans dio aglomerative-2',\n 'absorption/Properties/Group0 dio k-means-2',\n 'absorption/Properties/Group0 dio meanshift-2',\n 'absorption/Properties/Group0 dio birch-2',\n 'absorption/Properties/Group0 dio affinity-0.5',\n 'absorption/Properties/Group0 dio aglomerative-2',\n 'absorption/Properties/Group1 dio k-means-2',\n 'absorption/Properties/Group1 dio meanshift-2',\n 'absorption/Properties/Group1 dio birch-2',\n 'absorption/Properties/Group1 dio affinity-0.5',\n 'absorption/Properties/Group1 dio aglomerative-2',\n 'absorption/Properties/Group2 dio k-means-2',\n 'absorption/Properties/Group2 dio meanshift-2',\n 'absorption/Properties/Group2 dio birch-8',\n 'absorption/Properties/Group2 dio affinity-0.5',\n 'absorption/Properties/Group2 dio aglomerative-8',\n 'absorption/Properties/Group3 dio k-means-29',\n 'absorption/Properties/Group3 dio meanshift-2',\n 'absorption/Properties/Group3 dio birch-29',\n 'absorption/Properties/Group3 dio affinity-0.5',\n 'absorption/Properties/Group3 dio aglomerative-29',\n 'absorption/Properties/Group4 dio k-means-3',\n 'absorption/Properties/Group4 dio meanshift-2',\n 'absorption/Properties/Group4 dio birch-3',\n 'absorption/Properties/Group4 dio affinity-0.5',\n 'absorption/Properties/Group4 dio aglomerative-3',\n 'absorption/Properties/Group5 dio k-means-2',\n 'absorption/Properties/Group5 dio meanshift-2',\n 'absorption/Properties/Group5 dio birch-2',\n 'absorption/Properties/Group5 dio affinity-0.5',\n 'absorption/Properties/Group5 dio aglomerative-2',\n 'absorption/Properties/Group6 dio k-means-2',\n 'absorption/Properties/Group6 dio meanshift-2',\n 'absorption/Properties/Group6 dio birch-2',\n 'absorption/Properties/Group6 dio affinity-0.5',\n 'absorption/Properties/Group6 dio aglomerative-2',\n 'absorption/Properties/Group7 dio k-means-2',\n 'absorption/Properties/Group7 dio meanshift-2',\n 'absorption/Properties/Group7 dio birch-2',\n 'absorption/Properties/Group7 dio affinity-0.5',\n 'absorption/Properties/Group7 dio aglomerative-2',\n 'enantioselectivity/FFT/Group0 dio k-means-8',\n 'enantioselectivity/FFT/Group0 dio meanshift-2',\n 'enantioselectivity/FFT/Group0 dio birch-8',\n 'enantioselectivity/FFT/Group0 dio affinity-0.5',\n 'enantioselectivity/FFT/Group0 dio aglomerative-8',\n 'enantioselectivity/FFT/Group1 dio k-means-2',\n 'enantioselectivity/FFT/Group1 dio meanshift-2',\n 'enantioselectivity/FFT/Group1 dio birch-2',\n 'enantioselectivity/FFT/Group1 dio affinity-0.5',\n 'enantioselectivity/FFT/Group1 dio aglomerative-2',\n 'enantioselectivity/FFT/Group2 dio k-means-28',\n 'enantioselectivity/FFT/Group2 dio meanshift-2',\n 'enantioselectivity/FFT/Group2 dio birch-29',\n 'enantioselectivity/FFT/Group2 dio affinity-0.5',\n 'enantioselectivity/FFT/Group2 dio aglomerative-29',\n 'enantioselectivity/FFT/Group3 dio k-means-29',\n 'enantioselectivity/FFT/Group3 dio meanshift-2',\n 'enantioselectivity/FFT/Group3 dio birch-29',\n 'enantioselectivity/FFT/Group3 dio affinity-0.5',\n 'enantioselectivity/FFT/Group3 dio aglomerative-29',\n 'enantioselectivity/FFT/Group4 dio k-means-2',\n 'enantioselectivity/FFT/Group4 dio meanshift-2',\n 'enantioselectivity/FFT/Group4 dio birch-2',\n 'enantioselectivity/FFT/Group4 dio affinity-0.5',\n 'enantioselectivity/FFT/Group4 dio aglomerative-2',\n 'enantioselectivity/FFT/Group5 dio k-means-29',\n 'enantioselectivity/FFT/Group5 dio meanshift-2',\n 'enantioselectivity/FFT/Group5 dio birch-29',\n 'enantioselectivity/FFT/Group5 dio affinity-0.5',\n 'enantioselectivity/FFT/Group5 dio aglomerative-29',\n 'enantioselectivity/FFT/Group6 dio k-means-29',\n 'enantioselectivity/FFT/Group6 dio meanshift-2',\n 'enantioselectivity/FFT/Group6 dio birch-29',\n 'enantioselectivity/FFT/Group6 dio affinity-0.5',\n 'enantioselectivity/FFT/Group6 dio aglomerative-29',\n 'enantioselectivity/FFT/Group7 dio k-means-4',\n 'enantioselectivity/FFT/Group7 dio meanshift-2',\n 'enantioselectivity/FFT/Group7 dio birch-4',\n 'enantioselectivity/FFT/Group7 dio affinity-0.5',\n 'enantioselectivity/FFT/Group7 dio aglomerative-4',\n 'enantioselectivity/NLP/bepler dio k-means-2',\n 'enantioselectivity/NLP/bepler dio meanshift-2',\n 'enantioselectivity/NLP/bepler dio birch-2',\n 'enantioselectivity/NLP/bepler dio affinity-0.5',\n 'enantioselectivity/NLP/bepler dio aglomerative-2',\n 'enantioselectivity/NLP/esm dio k-means-28',\n 'enantioselectivity/NLP/esm dio meanshift-2',\n 'enantioselectivity/NLP/esm dio birch-29',\n 'enantioselectivity/NLP/esm dio affinity-0.5',\n 'enantioselectivity/NLP/esm dio aglomerative-29',\n 'enantioselectivity/NLP/fasttext dio k-means-24',\n 'enantioselectivity/NLP/fasttext dio meanshift-2',\n 'enantioselectivity/NLP/fasttext dio birch-7',\n 'enantioselectivity/NLP/fasttext dio affinity-0.5',\n 'enantioselectivity/NLP/fasttext dio aglomerative-24',\n 'enantioselectivity/NLP/plus_rnn dio k-means-3',\n 'enantioselectivity/NLP/plus_rnn dio meanshift-2',\n 'enantioselectivity/NLP/plus_rnn dio birch-29',\n 'enantioselectivity/NLP/plus_rnn dio affinity-0.5',\n 'enantioselectivity/NLP/plus_rnn dio aglomerative-29',\n 'enantioselectivity/NLP/prottrans dio k-means-28',\n 'enantioselectivity/NLP/prottrans dio meanshift-2',\n 'enantioselectivity/NLP/prottrans dio birch-29',\n 'enantioselectivity/NLP/prottrans dio affinity-0.5',\n 'enantioselectivity/NLP/prottrans dio aglomerative-29',\n 'enantioselectivity/Properties/Group0 dio k-means-8',\n 'enantioselectivity/Properties/Group0 dio meanshift-2',\n 'enantioselectivity/Properties/Group0 dio birch-8',\n 'enantioselectivity/Properties/Group0 dio affinity-0.5',\n 'enantioselectivity/Properties/Group0 dio aglomerative-8',\n 'enantioselectivity/Properties/Group1 dio k-means-2',\n 'enantioselectivity/Properties/Group1 dio meanshift-2',\n 'enantioselectivity/Properties/Group1 dio birch-29',\n 'enantioselectivity/Properties/Group1 dio affinity-0.5',\n 'enantioselectivity/Properties/Group1 dio aglomerative-29',\n 'enantioselectivity/Properties/Group2 dio k-means-29',\n 'enantioselectivity/Properties/Group2 dio meanshift-2',\n 'enantioselectivity/Properties/Group2 dio birch-29',\n 'enantioselectivity/Properties/Group2 dio affinity-0.5',\n 'enantioselectivity/Properties/Group2 dio aglomerative-29',\n 'enantioselectivity/Properties/Group3 dio k-means-29',\n 'enantioselectivity/Properties/Group3 dio meanshift-2',\n 'enantioselectivity/Properties/Group3 dio birch-29',\n 'enantioselectivity/Properties/Group3 dio affinity-0.5',\n 'enantioselectivity/Properties/Group3 dio aglomerative-29',\n 'enantioselectivity/Properties/Group4 dio k-means-2',\n 'enantioselectivity/Properties/Group4 dio meanshift-2',\n 'enantioselectivity/Properties/Group4 dio birch-2',\n 'enantioselectivity/Properties/Group4 dio affinity-0.5',\n 'enantioselectivity/Properties/Group4 dio aglomerative-2',\n 'enantioselectivity/Properties/Group5 dio k-means-29',\n 'enantioselectivity/Properties/Group5 dio meanshift-2',\n 'enantioselectivity/Properties/Group5 dio birch-29',\n 'enantioselectivity/Properties/Group5 dio affinity-0.5',\n 'enantioselectivity/Properties/Group5 dio aglomerative-29',\n 'enantioselectivity/Properties/Group6 dio k-means-4',\n 'enantioselectivity/Properties/Group6 dio meanshift-2',\n 'enantioselectivity/Properties/Group6 dio birch-29',\n 'enantioselectivity/Properties/Group6 dio affinity-0.5',\n 'enantioselectivity/Properties/Group6 dio aglomerative-29',\n 'enantioselectivity/Properties/Group7 dio k-means-4',\n 'enantioselectivity/Properties/Group7 dio meanshift-2',\n 'enantioselectivity/Properties/Group7 dio birch-4',\n 'enantioselectivity/Properties/Group7 dio affinity-0.5',\n 'enantioselectivity/Properties/Group7 dio aglomerative-4',\n 'localization/FFT/Group0 dio k-means-3',\n 'localization/FFT/Group0 dio meanshift-2',\n 'localization/FFT/Group0 dio birch-3',\n 'localization/FFT/Group0 dio affinity-0.5',\n 'localization/FFT/Group0 dio aglomerative-3',\n 'localization/FFT/Group1 dio k-means-3',\n 'localization/FFT/Group1 dio meanshift-2',\n 'localization/FFT/Group1 dio birch-3',\n 'localization/FFT/Group1 dio affinity-0.5',\n 'localization/FFT/Group1 dio aglomerative-3',\n 'localization/FFT/Group2 dio k-means-3',\n 'localization/FFT/Group2 dio meanshift-2',\n 'localization/FFT/Group2 dio birch-3',\n 'localization/FFT/Group2 dio affinity-0.5',\n 'localization/FFT/Group2 dio aglomerative-3',\n 'localization/FFT/Group3 dio k-means-3',\n 'localization/FFT/Group3 dio meanshift-2',\n 'localization/FFT/Group3 dio birch-3',\n 'localization/FFT/Group3 dio affinity-0.5',\n 'localization/FFT/Group3 dio aglomerative-3',\n 'localization/FFT/Group4 dio k-means-3',\n 'localization/FFT/Group4 dio meanshift-2',\n 'localization/FFT/Group4 dio birch-3',\n 'localization/FFT/Group4 dio affinity-0.5',\n 'localization/FFT/Group4 dio aglomerative-3',\n 'localization/FFT/Group5 dio k-means-3',\n 'localization/FFT/Group5 dio meanshift-2',\n 'localization/FFT/Group5 dio birch-3',\n 'localization/FFT/Group5 dio affinity-0.5',\n 'localization/FFT/Group5 dio aglomerative-3',\n 'localization/FFT/Group6 dio k-means-3',\n 'localization/FFT/Group6 dio meanshift-2',\n 'localization/FFT/Group6 dio birch-3',\n 'localization/FFT/Group6 dio affinity-0.5',\n 'localization/FFT/Group6 dio aglomerative-3',\n 'localization/FFT/Group7 dio k-means-3',\n 'localization/FFT/Group7 dio meanshift-2',\n 'localization/FFT/Group7 dio birch-3',\n 'localization/FFT/Group7 dio affinity-0.5',\n 'localization/FFT/Group7 dio aglomerative-3',\n 'localization/NLP/bepler dio k-means-2',\n 'localization/NLP/bepler dio meanshift-2',\n 'localization/NLP/bepler dio birch-2',\n 'localization/NLP/bepler dio affinity-0.5',\n 'localization/NLP/bepler dio aglomerative-2',\n 'localization/NLP/esm dio k-means-3',\n 'localization/NLP/esm dio meanshift-2',\n 'localization/NLP/esm dio birch-2',\n 'localization/NLP/esm dio affinity-0.5',\n 'localization/NLP/esm dio aglomerative-2',\n 'localization/NLP/fasttext dio k-means-3',\n 'localization/NLP/fasttext dio meanshift-2',\n 'localization/NLP/fasttext dio birch-3',\n 'localization/NLP/fasttext dio affinity-0.5',\n 'localization/NLP/fasttext dio aglomerative-3',\n 'localization/NLP/plus_rnn dio k-means-2',\n 'localization/NLP/plus_rnn dio meanshift-2',\n 'localization/NLP/plus_rnn dio birch-2',\n 'localization/NLP/plus_rnn dio affinity-0.5',\n 'localization/NLP/plus_rnn dio aglomerative-2',\n 'localization/NLP/prottrans dio k-means-2',\n 'localization/NLP/prottrans dio meanshift-2',\n 'localization/NLP/prottrans dio birch-2',\n 'localization/NLP/prottrans dio affinity-0.5',\n 'localization/NLP/prottrans dio aglomerative-2',\n 'localization/Properties/Group0 dio k-means-3',\n 'localization/Properties/Group0 dio meanshift-2',\n 'localization/Properties/Group0 dio birch-3',\n 'localization/Properties/Group0 dio affinity-0.5',\n 'localization/Properties/Group0 dio aglomerative-3',\n 'localization/Properties/Group1 dio k-means-3',\n 'localization/Properties/Group1 dio meanshift-2',\n 'localization/Properties/Group1 dio birch-3',\n 'localization/Properties/Group1 dio affinity-0.5',\n 'localization/Properties/Group1 dio aglomerative-3',\n 'localization/Properties/Group2 dio k-means-3',\n 'localization/Properties/Group2 dio meanshift-2',\n 'localization/Properties/Group2 dio birch-3',\n 'localization/Properties/Group2 dio affinity-0.5',\n 'localization/Properties/Group2 dio aglomerative-3',\n 'localization/Properties/Group3 dio k-means-3',\n 'localization/Properties/Group3 dio meanshift-2',\n 'localization/Properties/Group3 dio birch-3',\n 'localization/Properties/Group3 dio affinity-0.5',\n 'localization/Properties/Group3 dio aglomerative-3',\n 'localization/Properties/Group4 dio k-means-3',\n 'localization/Properties/Group4 dio meanshift-2',\n 'localization/Properties/Group4 dio birch-3',\n 'localization/Properties/Group4 dio affinity-0.5',\n 'localization/Properties/Group4 dio aglomerative-3',\n 'localization/Properties/Group5 dio k-means-3',\n 'localization/Properties/Group5 dio meanshift-2',\n 'localization/Properties/Group5 dio birch-3',\n 'localization/Properties/Group5 dio affinity-0.5',\n 'localization/Properties/Group5 dio aglomerative-3',\n 'localization/Properties/Group6 dio k-means-3',\n 'localization/Properties/Group6 dio meanshift-2',\n 'localization/Properties/Group6 dio birch-3',\n 'localization/Properties/Group6 dio affinity-0.5',\n 'localization/Properties/Group6 dio aglomerative-3',\n 'localization/Properties/Group7 dio k-means-3',\n 'localization/Properties/Group7 dio meanshift-2',\n 'localization/Properties/Group7 dio birch-3',\n 'localization/Properties/Group7 dio affinity-0.5',\n 'localization/Properties/Group7 dio aglomerative-3',\n 'T50/FFT/Group0 dio k-means-2',\n 'T50/FFT/Group0 dio meanshift-2',\n 'T50/FFT/Group0 dio birch-2',\n 'T50/FFT/Group0 dio affinity-0.5',\n 'T50/FFT/Group0 dio aglomerative-2',\n 'T50/FFT/Group1 dio k-means-2',\n 'T50/FFT/Group1 dio meanshift-2',\n 'T50/FFT/Group1 dio birch-2',\n 'T50/FFT/Group1 dio affinity-0.5',\n 'T50/FFT/Group1 dio aglomerative-2',\n 'T50/FFT/Group2 dio k-means-2',\n 'T50/FFT/Group2 dio meanshift-2',\n 'T50/FFT/Group2 dio birch-2',\n 'T50/FFT/Group2 dio affinity-0.5',\n 'T50/FFT/Group2 dio aglomerative-2',\n 'T50/FFT/Group3 dio k-means-2',\n 'T50/FFT/Group3 dio meanshift-2',\n 'T50/FFT/Group3 dio birch-2',\n 'T50/FFT/Group3 dio affinity-0.5',\n 'T50/FFT/Group3 dio aglomerative-2',\n 'T50/FFT/Group4 dio k-means-2',\n 'T50/FFT/Group4 dio meanshift-2',\n 'T50/FFT/Group4 dio birch-2',\n 'T50/FFT/Group4 dio affinity-0.5',\n 'T50/FFT/Group4 dio aglomerative-2',\n 'T50/FFT/Group5 dio k-means-2',\n 'T50/FFT/Group5 dio meanshift-2',\n 'T50/FFT/Group5 dio birch-2',\n 'T50/FFT/Group5 dio affinity-0.5',\n 'T50/FFT/Group5 dio aglomerative-2',\n 'T50/FFT/Group6 dio k-means-2',\n 'T50/FFT/Group6 dio meanshift-2',\n 'T50/FFT/Group6 dio birch-2',\n 'T50/FFT/Group6 dio affinity-0.5',\n 'T50/FFT/Group6 dio aglomerative-2',\n 'T50/FFT/Group7 dio k-means-2',\n 'T50/FFT/Group7 dio meanshift-2',\n 'T50/FFT/Group7 dio birch-2',\n 'T50/FFT/Group7 dio affinity-0.5',\n 'T50/FFT/Group7 dio aglomerative-2',\n 'T50/NLP/bepler dio k-means-3',\n 'T50/NLP/bepler dio meanshift-2',\n 'T50/NLP/bepler dio birch-2',\n 'T50/NLP/bepler dio affinity-0.5',\n 'T50/NLP/bepler dio aglomerative-2',\n 'T50/NLP/esm dio k-means-3',\n 'T50/NLP/esm dio meanshift-2',\n 'T50/NLP/esm dio birch-3',\n 'T50/NLP/esm dio affinity-0.5',\n 'T50/NLP/esm dio aglomerative-3',\n 'T50/NLP/fasttext dio k-means-28',\n 'T50/NLP/fasttext dio meanshift-2',\n 'T50/NLP/fasttext dio birch-10',\n 'T50/NLP/fasttext dio affinity-0.5',\n 'T50/NLP/fasttext dio aglomerative-10',\n 'T50/NLP/plus_rnn dio k-means-2',\n 'T50/NLP/plus_rnn dio meanshift-2',\n 'T50/NLP/plus_rnn dio birch-2',\n 'T50/NLP/plus_rnn dio affinity-0.5',\n 'T50/NLP/plus_rnn dio aglomerative-2',\n 'T50/NLP/prottrans dio k-means-3',\n 'T50/NLP/prottrans dio meanshift-2',\n 'T50/NLP/prottrans dio birch-3',\n 'T50/NLP/prottrans dio affinity-0.5',\n 'T50/NLP/prottrans dio aglomerative-3',\n 'T50/Properties/Group0 dio k-means-2',\n 'T50/Properties/Group0 dio meanshift-2',\n 'T50/Properties/Group0 dio birch-2',\n 'T50/Properties/Group0 dio affinity-0.5',\n 'T50/Properties/Group0 dio aglomerative-2',\n 'T50/Properties/Group1 dio k-means-2',\n 'T50/Properties/Group1 dio meanshift-2',\n 'T50/Properties/Group1 dio birch-2',\n 'T50/Properties/Group1 dio affinity-0.5',\n 'T50/Properties/Group1 dio aglomerative-2',\n 'T50/Properties/Group2 dio k-means-2',\n 'T50/Properties/Group2 dio meanshift-2',\n 'T50/Properties/Group2 dio birch-2',\n 'T50/Properties/Group2 dio affinity-0.5',\n 'T50/Properties/Group2 dio aglomerative-2',\n 'T50/Properties/Group3 dio k-means-2',\n 'T50/Properties/Group3 dio meanshift-2',\n 'T50/Properties/Group3 dio birch-2',\n 'T50/Properties/Group3 dio affinity-0.5',\n 'T50/Properties/Group3 dio aglomerative-2',\n 'T50/Properties/Group4 dio k-means-2',\n 'T50/Properties/Group4 dio meanshift-2',\n 'T50/Properties/Group4 dio birch-2',\n 'T50/Properties/Group4 dio affinity-0.5',\n 'T50/Properties/Group4 dio aglomerative-2',\n 'T50/Properties/Group5 dio k-means-2',\n 'T50/Properties/Group5 dio meanshift-2',\n 'T50/Properties/Group5 dio birch-2',\n 'T50/Properties/Group5 dio affinity-0.5',\n 'T50/Properties/Group5 dio aglomerative-2',\n 'T50/Properties/Group6 dio k-means-2',\n 'T50/Properties/Group6 dio meanshift-2',\n 'T50/Properties/Group6 dio birch-2',\n 'T50/Properties/Group6 dio affinity-0.5',\n 'T50/Properties/Group6 dio aglomerative-2',\n 'T50/Properties/Group7 dio k-means-2',\n 'T50/Properties/Group7 dio meanshift-2',\n 'T50/Properties/Group7 dio birch-2',\n 'T50/Properties/Group7 dio affinity-0.5',\n 'T50/Properties/Group7 dio aglomerative-2']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}